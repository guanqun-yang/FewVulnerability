import json
import random
import pathlib
import itertools

import numpy as np
import pandas as pd

from collections import defaultdict
from datasets import Dataset, load_dataset, load_metric
from datasets.dataset_dict import DatasetDict
from transformers import AutoConfig, AutoTokenizer, DataCollatorForTokenClassification

from sklearn.metrics import classification_report

from utils.data import SimpleNERDataset
from utils.common import get_line_cnt, compute_weighted_f1, remove_directories

from setting import setting

metric = load_metric("seqeval")
config = AutoConfig.from_pretrained(setting.config_path)
tokenizer = AutoTokenizer.from_pretrained(setting.tokenizer_path, config=config, add_prefix_space=True)

###########################################################################################
# necessary methods for NER

def tokenize(examples):
    padding = True   
    text_column_name = "tokens"
    label_column_name = "tags"
    label_to_id = setting.label_to_id

    tokenized_inputs = tokenizer(examples[text_column_name], padding=padding, truncation=True, is_split_into_words=True)
    return tokenized_inputs


def tokenize_and_align_labels(examples):
    padding = True   
    text_column_name = "tokens"
    label_column_name = "tags"
    label_to_id = setting.label_to_id

    # see doc for details: https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__ 
    tokenized_inputs = tokenizer(examples[text_column_name], padding=padding, truncation=True, is_split_into_words=True)
    labels = list()
    for i, label in enumerate(examples[label_column_name]):
        word_ids = tokenized_inputs.word_ids(batch_index=i)
        previous_word_idx = None
        label_ids = list()
        for word_idx in word_ids:
            if word_idx is None: label_ids.append(-100)
            elif word_idx != previous_word_idx: label_ids.append(label_to_id[label[word_idx]])
            else: label_ids.append(-100)
        
            previous_word_idx = word_idx
        
        labels.append(label_ids)
    tokenized_inputs["labels"] = labels
    return tokenized_inputs

#############################################################################################
# helper functions

def save_json_file(record_list, filename):
    result = ""
    for record in record_list:
        result += "%s\n" % json.dumps(record)
    
    with open(filename, "w") as fp: fp.write(result)


def load_json_file(filename):
    record_list = list()
    with open(filename, "r") as fp:
        for line in fp.readlines():
            record_list.append(json.loads(line))
    
    return record_list

###########################################################################################
# prepare data

def prepare_data(dataset):
    # mostly same as create_update_data(), modify the name only
    # - all the size and frac are handled when creating dataset
    # - pool.json will be created regardless
    df = dataset.df
    name_idx_dict = {"train": dataset.train_idx, "pool": dataset.pool_idx,
                     "eval": dataset.eval_idx, "test": dataset.test_idx}
    
    # handling directories
    # pathlib.Path().cwd() will be the directory where the function is invoked
    base_path = pathlib.Path().cwd() / pathlib.Path("data/")
    if not base_path.exists(): base_path.mkdir()

    base_path = base_path / pathlib.Path(dataset.category)
    if not base_path.exists(): base_path.mkdir()

    # creating json files
    for name, idx in name_idx_dict.items():
        # if any of the dataset.<split>_idx is empty, continue
        if len(idx) == 0: continue

        file_path = base_path / pathlib.Path("%s.json" % name)
        # for eval.json and test.json, only create them once
        if name in ["eval", "test"]:
            if not file_path.exists(): 
                record_list = create_json_file(df.loc[idx])
                save_json_file(record_list, file_path)
        # update train.json and pool.json every time dataset.train_idx and dataset.pool_idx get updated
        else:
            if (not file_path.exists()) or (get_line_cnt(file_path) != len(idx)):    
                record_list = create_json_file(df.loc[idx])
                save_json_file(record_list, file_path)


def initialize_data(datasets):
    tokenized_datasets = datasets.map(tokenize_and_align_labels, 
                                      batched=True,
                                      num_proc=None,
                                      load_from_cache_file=True)
    return tokenized_datasets


def create_tokenized_datasets(dataset, base_path=pathlib.Path("data/"), in_memory=False):
    # in_memory == False: train.json, eval.json, test.json and pool.json will be created under data/<category>
    # in_memory == True: no <split>.json file will be created, all the data preprocessing is done in memory
    if not in_memory:
        prepare_data(dataset)

        # the following paths MUST be same as the ones in prepare_data()
        category_data_path = base_path / pathlib.Path(dataset.category)
        data_files = {key: str(category_data_path / pathlib.Path("%s.json" % key)) 
                    for key in ["train", "eval", "test"]}

        datasets = load_dataset("json", data_files=data_files)
    else:
        df = dataset.df

        df["tokens"] = df.tuple.apply(lambda x: [tup[0] for tup in x])
        df["tags"] = df.tuple.apply(lambda x: [tup[1] for tup in x])

        datasets = DatasetDict({split: Dataset.from_pandas(df[df.name == split][["ID", "tokens", "tags"]].reset_index(drop=True)) 
                                       for split in ["train", "eval", "test"]})

    
    tokenized_datasets = initialize_data(datasets)
    return tokenized_datasets

########################################################################################
# prediction and evaluation

def predict_model(trainer, tokenized_datasets, name="eval"):
    label_to_id = setting.label_to_id
    label_list = setting.label_list

    # makei predictions
    # predictions: (dataset_size, max_len, num_classes)
    # label_ids: (dataset_size, max_len)
    predictions, labels, metrics = trainer.predict(tokenized_datasets[name])
    predictions = np.argmax(predictions, axis=2)

    y_pred = [[label_list[p] for (p, l) in zip(prediction, label) if l != -100]
              for prediction, label in zip(predictions, labels)]
    y_true = [[label_list[l] for (p, l) in zip(prediction, label) if l != -100]
              for prediction, label in zip(predictions, labels)]
    
    return y_true, y_pred


def evaluate_model(trainer, tokenized_datasets, name="eval"):
    label_list = setting.label_list

    y_true, y_pred = predict_model(trainer, tokenized_datasets, name=name)

    y_pred_list = list(itertools.chain(*y_pred))
    y_true_list = list(itertools.chain(*y_true))

    metric = classification_report(y_true=y_true_list, y_pred=y_pred_list, target_names=label_list, output_dict=True)
    metric_str = classification_report(y_true=y_true_list, y_pred=y_pred_list, target_names=label_list, output_dict=False)

    return metric, metric_str


def compute_metrics(p):
    label_list = setting.label_list
    
    predictions, labels = p
    predictions = np.argmax(predictions, axis=2)

    # Remove ignored index (special tokens)
    true_predictions = [
        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    true_labels = [
        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]

    # 1. original metric computation
    results = metric.compute(predictions=true_predictions, references=true_labels)

    # 2. compute marco f1
    y_pred_list = list(itertools.chain(*true_predictions))
    y_true_list = list(itertools.chain(*true_labels))

    metric_dict = classification_report(y_true=y_true_list, 
                                        y_pred=y_pred_list, 
                                        target_names=label_list, 
                                        output_dict=True)
    weighted_f1 = compute_weighted_f1(metric_dict, target_names=["SN", "SV"])

    # 3. record and return
    result_dict = {"weighted_f1": weighted_f1}
    for tag in ["SN", "SV"]:
        for metric_name, metric_val in metric_dict[tag].items():
            if metric_name == "support": continue
            result_dict[f"{tag}_{metric_name}"] = metric_val


    return result_dict